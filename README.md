# Transformers-As-Visual-Encoder
The goal of this project is to benchmark different Performer-architectures as well as local-attention Transformer-architectures (with different receptive fields) on the classification tasks (for different datasets: MNIST, CIFAR10, ImageNet, Places365). 

The code of Performer under PerformerModel folder is adapted from https://github.com/lucidrains/performer-pytorch
